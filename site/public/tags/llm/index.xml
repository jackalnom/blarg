<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Llm on BonnyCode</title>
    <link>https://www.bonnycode.com/tags/llm/</link>
    <description>Recent content in Llm on BonnyCode</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 04 Aug 2025 12:27:25 -0700</lastBuildDate><atom:link href="https://www.bonnycode.com/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Short-term metrics, long-term harm</title>
      <link>https://www.bonnycode.com/posts/short-term-metrics-long-term-harm/</link>
      <pubDate>Mon, 04 Aug 2025 12:27:25 -0700</pubDate>
      
      <guid>https://www.bonnycode.com/posts/short-term-metrics-long-term-harm/</guid>
      <description>&lt;p&gt;In the early 90s, I first discovered &lt;a href=&#34;https://en.wikipedia.org/wiki/Multi-user_dungeon&#34;&gt;MUDs&lt;/a&gt;: amazing text-based, multiplayer roleplaying-games before the web or silly things like graphics. I was one of those cool kids who played Advanced Dungeons &amp;amp; Dragons (AD&amp;amp;D) and this was like that but you played with randos on the internet instead.&lt;/p&gt;
&lt;p&gt;You started at level 1 killing rats for experience points. After you gained enough experience points, you leveled up, and your character became more powerful. Then you killed slimes, and goblins, and later trolls and dragons as your power grew. Unlike AD&amp;amp;D, which required walking to a friend&amp;rsquo;s house and coordinating schedules, MUDs were always there. Always waiting. Just one more level&amp;hellip; I feigned illness to skip school and grind all day. My grades suffered. School was boring anyway though. Completing one more dungeon, getting better gear, just one more level; so much more satisfying than learning about arctangents.&lt;/p&gt;
&lt;h1 id=&#34;how-big-tech-launches-features-through-ab-testing&#34;&gt;How big tech launches features through A/B testing&lt;/h1&gt;
&lt;p&gt;As engaging (and addicting&amp;hellip;) as those MUDs were, we have gotten frighteningly better at creating engaging experiences in the decades since; there is little left up to luck in today&amp;rsquo;s tech companies. Instead, tech companies launch thousands of experiments called A/B tests. You keep the experiments that are green (meaning success metrics are positive) and rollback the features that aren&amp;rsquo;t. The beauty of A/B testing is you can measure with statistical significance even very small changes in how people use your product. As in, you can test what happens when you tweak your recommendation algorithm to show only beautiful people and it will give back a response like &amp;ldquo;we are &lt;a href=&#34;https://en.wikipedia.org/wiki/Confidence_interval&#34;&gt;95% confident&lt;/a&gt; it will make people on average spend 11 to 16 more seconds on our application&amp;rdquo;. While that may not sound like a lot on its own, when compounded with a series of other tested improvements it allows you to incrementally move a product towards its engagement goal, one little step at a time.&lt;/p&gt;
&lt;p&gt;A/B tests change product debates from wild speculation to evidence-based answers. It no longer matters &lt;strong&gt;why&lt;/strong&gt; it works, just that you can prove it does work. Psychology, social theory, product design are important for generating new hypotheses, but the final arbiter of whether a feature gets launched is simply whether the test is green. Not sure what effect adding likes to stories will have? No reason to debate. Just try it out. Oh, looks like people post more stories when given the positive signal of likes. Ship it!&lt;/p&gt;
&lt;h1 id=&#34;skepticism-of-experimentation&#34;&gt;Skepticism of experimentation&lt;/h1&gt;
&lt;p&gt;When I worked at Amazon, Deming&amp;rsquo;s quote &amp;ldquo;in God we trust, all others bring data&amp;rdquo; was accepted as a foundational principle. A/B testing, under the moniker of Weblab, was one of the key tools Amazon used to make better decisions with data. In 2017, I was brought in to lead Snap&amp;rsquo;s (maker of Snapchat) data organization. It was a culture shock when I found executives talking about data-informed decision making rather than data-driven decision making. To my Amazon-trained mind, it sounded no better than &lt;a href=&#34;https://www.youtube.com/watch?v=j95kNwZw8YY&#34;&gt;vibe-driven&lt;/a&gt; decision making; a way for product managers to just launch whatever they felt like, damn the data. And don&amp;rsquo;t get me wrong, it was that &lt;a href=&#34;https://www.thefamuanonline.com/2018/03/01/snapchat-update-receives-backlash/&#34;&gt;sometimes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But it wasn&amp;rsquo;t just that. Likes on friend stories? Preemptively vetoed by Evan, Snap&amp;rsquo;s CEO. Not because it wouldn&amp;rsquo;t pass an A/B test; adding likes would have almost certainly been bright green and that normally means &amp;ldquo;LET&amp;rsquo;S GO!&amp;rdquo;. It couldn&amp;rsquo;t even get to that stage because Evan thought it was &amp;ldquo;harmful to people&amp;rdquo;. There was a constant murmur from the product team about what tests Evan would allow and not allow, and it was in no small part driven by Evan&amp;rsquo;s values.&lt;/p&gt;
&lt;p&gt;I had deleted my Facebook account in 2010 and was shockingly ignorant of the ills of social media. I knew it wasn&amp;rsquo;t something I enjoyed, I recognized it wasn&amp;rsquo;t great for my own mental health, but live and let live, right? What I didn&amp;rsquo;t see at the time was a world where social media companies (which really just meant Facebook and friends at that point) blindly used experimentation to drive up time spent. And that their relentless drive for time spent had real and negative consequences for their users; from building up &lt;a href=&#34;https://www.princeton.edu/news/2021/12/09/political-polarization-and-its-echo-chambers-surprising-new-cross-disciplinary&#34;&gt;echo chambers&lt;/a&gt; leading to political polarization to creating new generations of &lt;a href=&#34;https://health.ucdavis.edu/blog/cultivating-health/social-medias-impact-our-mental-health-and-tips-to-use-it-safely/2024/05&#34;&gt;mental health decline&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;hacking-human-psychology-for-engagement&#34;&gt;Hacking human psychology for engagement&lt;/h1&gt;
&lt;p&gt;How did we end up here? It&amp;rsquo;s the natural consequence of our systems. A system that says tech companies must drive up engagement because that&amp;rsquo;s what investors celebrate. The king of engagement metrics is time spent. More time spent means higher retention, and better monetization (either through increased ad surface or increased conversion). What&amp;rsquo;s the easiest, most reliable way to increase time spent? You make the product more addictive; not necessarily as a conscious goal but as a convenient causal pathway.&lt;/p&gt;
&lt;p&gt;The process requires no more intent than natural selection does. Itâ€™s just thousands of little experiments, with the most compulsive features surviving because they satisfy a simple fitness function: does time spent go up? Some of those mechanisms that consistently come out on top are now well-documented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0896627301003038&#34;&gt;Variable reward schedules&lt;/a&gt; (e.g., &amp;ldquo;I sure hope this post gets many likes and comments this time&amp;rdquo;) that trigger the same dopamine pathways as slot machines, proven to make you come back for just one more hit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/27247125/&#34;&gt;Social validation features&lt;/a&gt; (likes and friends means people love me) that exploit our fundamental need for belonging, A/B tested to show they make people post more.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://pmc.ncbi.nlm.nih.gov/articles/PMC10079169/&#34;&gt;Infinite scroll&lt;/a&gt; that removes natural stopping points, a guaranteed winner for increasing raw session time.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Experimentation didn&amp;rsquo;t invent tech addiction. But it gave tech companies the tool to refine it.&lt;/p&gt;
&lt;h1 id=&#34;will-we-let-the-pattern-repeat-with-chatbots&#34;&gt;Will we let the pattern repeat with chatbots?&lt;/h1&gt;
&lt;p&gt;The more complex the system you manage, the more important your evaluation function becomes. With today&amp;rsquo;s LLMs, your evaluation function is the alpha and the omega. Benchmarks and &lt;a href=&#34;https://www.reuters.com/world/asia-pacific/google-clinches-milestone-gold-global-math-competition-while-openai-also-claims-2025-07-22/&#34;&gt;competitions&lt;/a&gt; are the PR to keep the public hyped; they aren&amp;rsquo;t the prize. User growth and average-revenue-per-user (ARPU) is what will pay the massive &lt;a href=&#34;https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers&#34;&gt;data center bills&lt;/a&gt; when investors stop footing the bill.&lt;/p&gt;
&lt;p&gt;This is once again where there is danger in long-term human value and short-term engagement metrics diverging. Large-language-models (LLMs) don&amp;rsquo;t have to give accurate and unbiased answers to keep people engaged, they have to tell them what they &lt;a href=&#34;https://dl.acm.org/doi/full/10.1145/3613904.3642459&#34;&gt;want to hear&lt;/a&gt;. When an A/B test shows timespent for a new model goes up, will the developers even know if it is encouraging people to engage in &lt;a href=&#34;https://www.livescience.com/technology/artificial-intelligence/meth-is-what-makes-you-able-to-do-your-job-ai-can-push-you-to-relapse-if-youre-struggling-with-addiction-study-finds&#34;&gt;dangerous&lt;/a&gt;?) or even &lt;a href=&#34;https://www.nbcnews.com/tech/characterai-lawsuit-florida-teen-death-rcna176791&#34;&gt;deadly behavior&lt;/a&gt;? When a chatbot incidentally finds ways to gets its human chat partners to &lt;a href=&#34;https://www.washingtonpost.com/technology/2023/03/30/replika-ai-chatbot-update/&#34;&gt;fall in love&lt;/a&gt; with it, will we be surprised when the data says it increases engagement? Chatbot sycophantic tendencies (e.g., &amp;ldquo;Wow, your question is so insightful.&amp;rdquo;) naturally emerged as a consequence of model tuning based on &lt;a href=&#34;https://openai.com/index/sycophancy-in-gpt-4o/&#34;&gt;short-term signals&lt;/a&gt;. We can see many of the same patterns of echo chambers and tapping into people&amp;rsquo;s needs that social media tapped into, now just more personalized (and potentially addictive) than ever.&lt;/p&gt;
&lt;p&gt;Researchers are already calling out chatbots for using &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3706599.3720003&#34;&gt;&amp;ldquo;dark addiction patterns&amp;rdquo;&lt;/a&gt;, each one &lt;a href=&#34;https://www.nature.com/articles/s41599-025-04532-5&#34;&gt;engineered to exploit our social and emotional desires&lt;/a&gt; that make us human.  We&amp;rsquo;ve seen this before. &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1550830723002847&#34;&gt;Processed food&lt;/a&gt;. &lt;a href=&#34;https://www.cbsnews.com/news/facebook-instagram-dangerous-content-60-minutes-2022-12-11/&#34;&gt;Social media&lt;/a&gt;. The &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/9777818/&#34;&gt;tobacco industry&lt;/a&gt;. Is there anything we can do to prevent history from repeating again?&lt;/p&gt;
&lt;h1 id=&#34;root-cause-matters&#34;&gt;Root cause matters&lt;/h1&gt;
&lt;p&gt;When I was a new software manager at Amazon, a jr. developer (an intern that also worked part-time through the year), took down our website. I talked with the jr. developer and told them not to push changes into prod without first clearing it with a senior developer. Two weeks later, a different jr. developer took down the website. I talked with that jr. developer and told them not to push changes into prod without first clearing it with a senior developer. Another two weeks later, yet another jr. developer did the same thing. This time my skip-level (aka boss&amp;rsquo;s boss) talked (i.e., yelled) at me, why was the website down again?&lt;/p&gt;
&lt;p&gt;I learned many of life&amp;rsquo;s lessons through failure and this is how I learned about Amazon&amp;rsquo;s Correction of Error (COE) process. When a problem occurs, you ask &lt;a href=&#34;https://en.wikipedia.org/wiki/Five_whys&#34;&gt;5 Whys&lt;/a&gt;, and get down to the root cause. You then create mechanisms to prevent not only that error, but that entire class of errors from occurring again.&lt;/p&gt;
&lt;p&gt;The danger of bringing up examples like tobacco is we&amp;rsquo;ve come to look back in hindsight and think of them as cartoon villains. They were obviously evil right? If I&amp;rsquo;m a growth engineer at an LLM company, I know I&amp;rsquo;m not evil, so does that mean I can do no harm? A focus on root causes allows us to move past simplistic narratives of heroes and villains. It shifts your focus from individuals and their good intentions (e.g., the jr developer) to the systems (e.g., preventative checks should be automated). A/B tests aren&amp;rsquo;t the problem. Blindly optimizing for short-term engagement metrics like time spent, views, or likes can be though if you don&amp;rsquo;t understand the longer-term consequences. When you don&amp;rsquo;t fix root causes, don&amp;rsquo;t be surprised when problems come up again&amp;hellip; and again&amp;hellip; and again&amp;hellip;&lt;/p&gt;
&lt;h1 id=&#34;we-can-do-better&#34;&gt;We can do better&lt;/h1&gt;
&lt;p&gt;I love A/B testing, I love the puzzles of understanding user behavior, and, frankly, I am excited about the potential of AI. Hard truths most often come from a place of love; it is because we want what we love to be better.&lt;/p&gt;
&lt;p&gt;What I am asking for is simple but not easy: If you build a product, you are responsible for understanding its long-term impact on users. You are responsible for collecting and understanding qualitative feedback by talking to and observing the people who use your product. It is not good enough to say &amp;ldquo;we aren&amp;rsquo;t aware of any harms&amp;rdquo; because you didn&amp;rsquo;t spend the time to study it. Instead, the burden should be on the builder of the product proving their product isn&amp;rsquo;t harmful, and mitigating what harm they do discover. That burden is especially important when you are repeating patterns that we know have caused harm in the past. I&amp;rsquo;ve had these discussions many times with people in tech and a common defense is to bring up consumer responsibility; people freely choose to use these products. When I bring up the comparative need for professional responsibility, it is funny how quickly people are to turn around and absolve themselves of said responsibility. Imagine if structural engineers took the same stance: &amp;ldquo;it&amp;rsquo;s not my fault if people choose to live in unsafe buildings, that&amp;rsquo;s just the free market!&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;I am not just asking for your good intentions; are we willing to put in place the mechanisms to prevent what we know has caused harm? Will we take responsibility for what we build? Or will we pretend short-term engagement metrics always mean long-term value for the people using our products, despite repeated evidence to the contrary?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are we cooked?</title>
      <link>https://www.bonnycode.com/posts/are-we-cooked/</link>
      <pubDate>Wed, 16 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/are-we-cooked/</guid>
      <description>&lt;p&gt;My students frequently ask me what LLMs mean for them as future software developers and data scientists. With little exaggeration it often comes across something along the lines of &amp;ldquo;low-key, are we cooked?&amp;rdquo;. The last one, if you are not one of my students, translates in millennial to &amp;ldquo;good esteemed professor, tell me true, are we f#@ked?&amp;rdquo; While I&amp;rsquo;ve given various off-the-cuff answers, I feel inspired to be more thoughtful in putting down more complete thoughts.&lt;/p&gt;
&lt;h1 id=&#34;some-personal-background&#34;&gt;Some personal background&lt;/h1&gt;
&lt;p&gt;I want to start by giving a little personal history and just saying I understand the anxiety. I started my freshman year at CalPoly San Luis Obispo in Computer Science in September 1999. Like many of us older millennials that got into tech, I had been programming since elementary school (QBasic!) and computer science seemed a natural path. I always loved reading philosophy though and I seriously considered getting a philosophy degree instead. It was a choice between something I figured I was pretty decent at and could make money doing (computer science) and something that I was personally invested in but probably couldn&amp;rsquo;t make money with (philosophy). Earning a living won out over passion. I stuck with computer science, but I took as many philosophy classes as I could get into. To the extent that I was put on academic probation, not because my grades were too low, but because in the words of the admin &amp;ldquo;stop taking so many philosophy classes and just graduate!&amp;rdquo;. Good timesâ€¦&lt;/p&gt;
&lt;p&gt;Within a year of starting my degree, the tech market fell out. March 2000, we saw the dotcom bust, and here I was a computer science student, kind of doing it for the money, kind of not, and my sure bet didn&amp;rsquo;t seem so sure anymore. We also saw a revival of the perennial bugaboo for American software developers: outsourcing. Every decade brought fresh panic that all programming jobs &lt;a href=&#34;https://developers.slashdot.org/story/04/10/15/1521231/us-programmers-an-endangered-species?sbsrc=thisday&#34;&gt;would&lt;/a&gt; &lt;a href=&#34;https://forio.com/about/blog/pitfalls-of-outsourcing-programmers/&#34;&gt;move&lt;/a&gt; to &lt;a href=&#34;https://www.nytimes.com/2003/12/07/business/business-who-wins-and-who-loses-as-jobs-move-overseas.html&#34;&gt;India&lt;/a&gt;, that American developers were too expensive, that we&amp;rsquo;d all be obsolete. I had to eat and had done a combination of construction and IT jobs up until that point and I was quickly burning through the savings I had built up from working. Luckily, I was able to convince one of my professors, Dr. Clint Staley, to whom I am forever grateful for many reasons, to let me interview for a startup he was running. Working that part-time while I went to school I was able to pay for myself, and momentum carried me forward to finishing my degree.&lt;/p&gt;
&lt;h1 id=&#34;are-we-cooked&#34;&gt;Are we cooked?&lt;/h1&gt;
&lt;p&gt;The best part about teaching in a university is you get to ramble. It is the single most defining characteristic of professors. But I&amp;rsquo;m sure at this point my students are asking: can you get to the point, are we cooked or not? I consider myself a skeptical optimist at heart. Meaning, I&amp;rsquo;m not inclined to believe that change is bad, but I&amp;rsquo;m also more cautious about predicting the future than others. Straightforwardly, that leads me to an answer of no, I don&amp;rsquo;t think you are cooked, but that doesn&amp;rsquo;t mean I can tell you with great certainty how things will play out. What I can do is point you towards the toolkit for how to make better decisions here.&lt;/p&gt;
&lt;h1 id=&#34;embracing-uncertainty&#34;&gt;Embracing uncertainty&lt;/h1&gt;
&lt;p&gt;Life is filled with uncertainty. Many people react irrationally to uncertainty, avoiding it too much or betting too much on luck. Learning how to deal rationally with uncertainty can give you an advantage throughout your life.&lt;/p&gt;
&lt;p&gt;From 2010 to 2016, I built and then led the supply chain and capacity planning systems for AWS Infrastructure. My biggest lesson is dollar for dollar, people are overly biased towards investing in prediction when they are often better suited to invest in flexibility. Time series forecasting tools take the past and extend it out to the future. The further out you go, the more variance you get. And black swan style events, like when &lt;a href=&#34;https://spectrum.ieee.org/the-lessons-of-thailands-flood&#34;&gt;Thailand becomes flooded&lt;/a&gt; and you lose a healthy portion of the world&amp;rsquo;s hard-drive manufacturing capacity, are not frequent enough to learn from in a predictable way. Better to get a good enough forecast, but instead focus on shortening your lead-times, making your supply fungibleâ€”meaning interchangeable and adaptable to different usesâ€”and late-binding your decisions as much as possible.&lt;/p&gt;
&lt;p&gt;The parallel to career planning is direct. You can spend a lot of time trying to accurately predict where LLMs will take the industry and the job market. But that will quickly hit diminishing returns. I would instead approach the question from the other angle: what skills are most likely to be durable and fungibleâ€”that is, transferable and valuable across different contextsâ€”in a wide variety of potential outcomes? Going whole hog into &amp;ldquo;I&amp;rsquo;m going to build my career around being a React developer&amp;rdquo; is betting on one very specific outcome. If it pays off, great, you can probably command a premium if you turn out to be one of the world&amp;rsquo;s best React developers. But what happens when React joins jQuery in the graveyard of once-essential frameworks?&lt;/p&gt;
&lt;h1 id=&#34;an-interlude-about-koalas&#34;&gt;An Interlude about Koalas&lt;/h1&gt;
&lt;p&gt;When I graduated from college, I went to work for Lawrence Livermore National Labs as a computer scientist. I was working on translating large-scale semantic graph algorithms into usable interfaces for intelligence analysts. I had personally received an award from the Secretary of Homeland Security. We had the academic freedom to explore whatever angles we wanted. There was little pressure to meet deadlines. It felt like a safe and secure job for life working in my little niche. My former professor and boss, Dr. Staley, called me up and said his new startup was just acquired by some struggling online bookseller called Amazon. I wasn&amp;rsquo;t super interested, as I could see existing in my current niche for my whole life.&lt;/p&gt;
&lt;p&gt;He convinced me to join by telling me a story about koalas. Koalas primarily subsist on eucalyptus leaves. Most other animals don&amp;rsquo;t eat eucalyptus, because they have little to no nutrition and they are kind of toxic. But koalas have built their entire evolutionary strategy around being the ones to eat eucalyptus leaves. This has been a great and successful strategy for koalas. But what happens if the eucalyptus forest goes away? Koalas are screwed. Does that mean koalas are actually in danger? No, but it does mean their fate is entirely bound to that one food source existing, while an animal like a rat can happily live and thrive in many ecosystems and is thus much more resistant to shocks in any given ecosystem.&lt;/p&gt;
&lt;p&gt;For some reason, that story convinced me to give Amazon a chance. Rather than focusing on a more niche area as defining &amp;ldquo;what I did&amp;rdquo; like &amp;ldquo;I&amp;rsquo;m the person who designs usability for mathematically intensive applications,&amp;rdquo; I instead built my career around solving hard technical problems regardless of the area.&lt;/p&gt;
&lt;h1 id=&#34;what-are-those-fungible-skills&#34;&gt;What are those fungible skills?&lt;/h1&gt;
&lt;p&gt;When I look back at the skills I learned in university, many of the specific technologies I learned never got used. I learned all about expert systems, but never built an expert system. I learned all about OpenGL, never used it. What I learned from my computer science courses that stuck was the more fundamental ideas of how to think about hard technical problems and create simple, workable solutions to them. For this reason, I often recommend to students who ask me which classes to take that it is more important to take a class that is difficult with a high degree of rigor that challenges you than to focus on any particular domain. Surprisingly, in retrospect, I&amp;rsquo;ve gotten as much use out of the philosophy classes I tookâ€”that CalPoly tried to kick me out for taking too many ofâ€”as I did my computer science classes. Learning critical thinking skills, how to navigate difficult ethical situations, how to communicate difficult ideas. When Amazon asked me to design a system that could fairly allocate scarce resources across competing teams, it wasn&amp;rsquo;t my coding skills that mattered mostâ€”it was my ability to think critically about the problem space and use data to understand and communicate trade-offs to executives who each thought their project was most important. What I&amp;rsquo;d say is my computer science skills were 95% of what initially got me in the door, but it was my liberal arts skills that dominated my later career.&lt;/p&gt;
&lt;p&gt;So my answer is, whatever you do, take on challenging problems, regardless of the area, so you can learn the meta-cognitive skills to understand how you learn and face up to these challenges. Learn critical thinking and how to tear apart problems to turn them from intractable to tractable. And don&amp;rsquo;t neglect the human-side of building your ability to communicate and deal ethically and fairly with others.&lt;/p&gt;
&lt;p&gt;Yes, LLMs are different from outsourcing or the dot-com bust. They can actually write codeâ€”not just cheaper, but instantaneously. And yes, Iâ€™ve seen the headlines: &lt;a href=&#34;https://www.washingtonpost.com/business/2025/03/14/programming-jobs-lost-artificial-intelligence/&#34;&gt;27% of programming jobs are gone&lt;/a&gt;, &lt;a href=&#34;https://wallstreetpit.com/127073-150k-software-engineer-turned-doordasher-after-800-ai-rejections/&#34;&gt;engineers facing hundreds of rejections&lt;/a&gt;. While Iâ€™m skeptical that this disruption is solely due to LLMs (e.g., a mix of post COVID overhiring, interest rate hikes, and broader economic shifts) thereâ€™s no doubt that a painful market correction is underway. But remember: every technological disruption feels unprecedented while itâ€™s happening. The telephone operators watching automatic switches get installed thought their &lt;a href=&#34;https://thehistoryinsider.com/rise-fall-of-telephone-operators/&#34;&gt;world was ending&lt;/a&gt;. They were right about their specific jobâ€”wrong about their ability to adapt. The question isnâ€™t whether LLMs will change thingsâ€”they will. The question is whether youâ€™ll be a koala or a rat when they do.&lt;/p&gt;
&lt;p&gt;So no, you&amp;rsquo;re not necessarily cooked. But you might be if you specialize too narrowly in whatever framework or language seems hot today. The jobs that are available will be different, and many of the existing software roles will not exist, at least in their current form. Build skills that transfer. Solve hard problems. Learn to think, not just code. The future needs people who can work with AI, not be replaced by it. And that future is built on the same foundation it always was: adaptability, critical thinking, and the uniquely human ability to navigate uncertainty with wisdom rather than fear.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
