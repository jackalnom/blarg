<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on BonnyCode</title>
    <link>https://www.bonnycode.com/</link>
    <description>Recent content in Home on BonnyCode</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://www.bonnycode.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Short-term metrics, long-term harm</title>
      <link>https://www.bonnycode.com/posts/short-term-metrics-long-term-harm/</link>
      <pubDate>Mon, 04 Aug 2025 12:27:25 -0700</pubDate>
      
      <guid>https://www.bonnycode.com/posts/short-term-metrics-long-term-harm/</guid>
      <description>&lt;p&gt;In the early 90s, I first discovered &lt;a href=&#34;https://en.wikipedia.org/wiki/Multi-user_dungeon&#34;&gt;MUDs&lt;/a&gt;: amazing text-based, multiplayer roleplaying-games before the web or silly things like graphics. I was one of those cool kids who played Advanced Dungeons &amp;amp; Dragons (AD&amp;amp;D) and this was like that but you played with randos on the internet instead.&lt;/p&gt;
&lt;p&gt;You started at level 1 killing rats for experience points. After you gained enough experience points, you leveled up, and your character became more powerful. Then you killed slimes, and goblins, and later trolls and dragons as your power grew. Unlike AD&amp;amp;D, which required walking to a friend&amp;rsquo;s house and coordinating schedules, MUDs were always there. Always waiting. Just one more level&amp;hellip; I feigned illness to skip school and grind all day. My grades suffered. School was boring anyway though. Completing one more dungeon, getting better gear, just one more level; so much more satisfying than learning about arctangents.&lt;/p&gt;
&lt;h1 id=&#34;how-big-tech-launches-features-through-ab-testing&#34;&gt;How big tech launches features through A/B testing&lt;/h1&gt;
&lt;p&gt;As engaging (and addicting&amp;hellip;) as those MUDs were, we have gotten frighteningly better at creating engaging experiences in the decades since; there is little left up to luck in today&amp;rsquo;s tech companies. Instead, tech companies launch thousands of experiments called A/B tests. You keep the experiments that are green (meaning success metrics are positive) and rollback the features that aren&amp;rsquo;t. The beauty of A/B testing is you can measure with statistical significance even very small changes in how people use your product. As in, you can test what happens when you tweak your recommendation algorithm to show only beautiful people and it will give back a response like &amp;ldquo;we are &lt;a href=&#34;https://en.wikipedia.org/wiki/Confidence_interval&#34;&gt;95% confident&lt;/a&gt; it will make people on average spend 11 to 16 more seconds on our application&amp;rdquo;. While that may not sound like a lot on its own, when compounded with a series of other tested improvements it allows you to incrementally move a product towards its engagement goal, one little step at a time.&lt;/p&gt;
&lt;p&gt;A/B tests change product debates from wild speculation to evidence-based answers. It no longer matters &lt;strong&gt;why&lt;/strong&gt; it works, just that you can prove it does work. Psychology, social theory, product design are important for generating new hypotheses, but the final arbiter of whether a feature gets launched is simply whether the test is green. Not sure what effect adding likes to stories will have? No reason to debate. Just try it out. Oh, looks like people post more stories when given the positive signal of likes. Ship it!&lt;/p&gt;
&lt;h1 id=&#34;skepticism-of-experimentation&#34;&gt;Skepticism of experimentation&lt;/h1&gt;
&lt;p&gt;When I worked at Amazon, Deming&amp;rsquo;s quote &amp;ldquo;in God we trust, all others bring data&amp;rdquo; was accepted as a foundational principle. A/B testing, under the moniker of Weblab, was one of the key tools Amazon used to make better decisions with data. In 2017, I was brought in to lead Snap&amp;rsquo;s (maker of Snapchat) data organization. It was a culture shock when I found executives talking about data-informed decision making rather than data-driven decision making. To my Amazon-trained mind, it sounded no better than &lt;a href=&#34;https://www.youtube.com/watch?v=j95kNwZw8YY&#34;&gt;vibe-driven&lt;/a&gt; decision making; a way for product managers to just launch whatever they felt like, damn the data. And don&amp;rsquo;t get me wrong, it was that &lt;a href=&#34;https://www.thefamuanonline.com/2018/03/01/snapchat-update-receives-backlash/&#34;&gt;sometimes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But it wasn&amp;rsquo;t just that. Likes on friend stories? Preemptively vetoed by Evan, Snap&amp;rsquo;s CEO. Not because it wouldn&amp;rsquo;t pass an A/B test; adding likes would have almost certainly been bright green and that normally means &amp;ldquo;LET&amp;rsquo;S GO!&amp;rdquo;. It couldn&amp;rsquo;t even get to that stage because Evan thought it was &amp;ldquo;harmful to people&amp;rdquo;. There was a constant murmur from the product team about what tests Evan would allow and not allow, and it was in no small part driven by Evan&amp;rsquo;s values.&lt;/p&gt;
&lt;p&gt;I had deleted my Facebook account in 2010 and was shockingly ignorant of the ills of social media. I knew it wasn&amp;rsquo;t something I enjoyed, I recognized it wasn&amp;rsquo;t great for my own mental health, but live and let live, right? What I didn&amp;rsquo;t see at the time was a world where social media companies (which really just meant Facebook and friends at that point) blindly used experimentation to drive up time spent. And that their relentless drive for time spent had real and negative consequences for their users; from building up &lt;a href=&#34;https://www.princeton.edu/news/2021/12/09/political-polarization-and-its-echo-chambers-surprising-new-cross-disciplinary&#34;&gt;echo chambers&lt;/a&gt; leading to political polarization to creating new generations of &lt;a href=&#34;https://health.ucdavis.edu/blog/cultivating-health/social-medias-impact-our-mental-health-and-tips-to-use-it-safely/2024/05&#34;&gt;mental health decline&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;hacking-human-psychology-for-engagement&#34;&gt;Hacking human psychology for engagement&lt;/h1&gt;
&lt;p&gt;How did we end up here? It&amp;rsquo;s the natural consequence of our systems. A system that says tech companies must drive up engagement because that&amp;rsquo;s what investors celebrate. The king of engagement metrics is time spent. More time spent means higher retention, and better monetization (either through increased ad surface or increased conversion). What&amp;rsquo;s the easiest, most reliable way to increase time spent? You make the product more addictive; not necessarily as a conscious goal but as a convenient causal pathway.&lt;/p&gt;
&lt;p&gt;The process requires no more intent than natural selection does. It’s just thousands of little experiments, with the most compulsive features surviving because they satisfy a simple fitness function: does time spent go up? Some of those mechanisms that consistently come out on top are now well-documented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0896627301003038&#34;&gt;Variable reward schedules&lt;/a&gt; (e.g., &amp;ldquo;I sure hope this post gets many likes and comments this time&amp;rdquo;) that trigger the same dopamine pathways as slot machines, proven to make you come back for just one more hit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/27247125/&#34;&gt;Social validation features&lt;/a&gt; (likes and friends means people love me) that exploit our fundamental need for belonging, A/B tested to show they make people post more.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://pmc.ncbi.nlm.nih.gov/articles/PMC10079169/&#34;&gt;Infinite scroll&lt;/a&gt; that removes natural stopping points, a guaranteed winner for increasing raw session time.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Experimentation didn&amp;rsquo;t invent tech addiction. But it gave tech companies the tool to refine it.&lt;/p&gt;
&lt;h1 id=&#34;will-we-let-the-pattern-repeat-with-chatbots&#34;&gt;Will we let the pattern repeat with chatbots?&lt;/h1&gt;
&lt;p&gt;The more complex the system you manage, the more important your evaluation function becomes. With today&amp;rsquo;s LLMs, your evaluation function is the alpha and the omega. Benchmarks and &lt;a href=&#34;https://www.reuters.com/world/asia-pacific/google-clinches-milestone-gold-global-math-competition-while-openai-also-claims-2025-07-22/&#34;&gt;competitions&lt;/a&gt; are the PR to keep the public hyped; they aren&amp;rsquo;t the prize. User growth and average-revenue-per-user (ARPU) is what will pay the massive &lt;a href=&#34;https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-cost-of-compute-a-7-trillion-dollar-race-to-scale-data-centers&#34;&gt;data center bills&lt;/a&gt; when investors stop footing the bill.&lt;/p&gt;
&lt;p&gt;This is once again where there is danger in long-term human value and short-term engagement metrics diverging. Large-language-models (LLMs) don&amp;rsquo;t have to give accurate and unbiased answers to keep people engaged, they have to tell them what they &lt;a href=&#34;https://dl.acm.org/doi/full/10.1145/3613904.3642459&#34;&gt;want to hear&lt;/a&gt;. When an A/B test shows timespent for a new model goes up, will the developers even know if it is encouraging people to engage in &lt;a href=&#34;https://www.livescience.com/technology/artificial-intelligence/meth-is-what-makes-you-able-to-do-your-job-ai-can-push-you-to-relapse-if-youre-struggling-with-addiction-study-finds&#34;&gt;dangerous&lt;/a&gt;?) or even &lt;a href=&#34;https://www.nbcnews.com/tech/characterai-lawsuit-florida-teen-death-rcna176791&#34;&gt;deadly behavior&lt;/a&gt;? When a chatbot incidentally finds ways to gets its human chat partners to &lt;a href=&#34;https://www.washingtonpost.com/technology/2023/03/30/replika-ai-chatbot-update/&#34;&gt;fall in love&lt;/a&gt; with it, will we be surprised when the data says it increases engagement? Chatbot sycophantic tendencies (e.g., &amp;ldquo;Wow, your question is so insightful.&amp;rdquo;) naturally emerged as a consequence of model tuning based on &lt;a href=&#34;https://openai.com/index/sycophancy-in-gpt-4o/&#34;&gt;short-term signals&lt;/a&gt;. We can see many of the same patterns of echo chambers and tapping into people&amp;rsquo;s needs that social media tapped into, now just more personalized (and potentially addictive) than ever.&lt;/p&gt;
&lt;p&gt;Researchers are already calling out chatbots for using &lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3706599.3720003&#34;&gt;&amp;ldquo;dark addiction patterns&amp;rdquo;&lt;/a&gt;, each one &lt;a href=&#34;https://www.nature.com/articles/s41599-025-04532-5&#34;&gt;engineered to exploit our social and emotional desires&lt;/a&gt; that make us human.  We&amp;rsquo;ve seen this before. &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1550830723002847&#34;&gt;Processed food&lt;/a&gt;. &lt;a href=&#34;https://www.cbsnews.com/news/facebook-instagram-dangerous-content-60-minutes-2022-12-11/&#34;&gt;Social media&lt;/a&gt;. The &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/9777818/&#34;&gt;tobacco industry&lt;/a&gt;. Is there anything we can do to prevent history from repeating again?&lt;/p&gt;
&lt;h1 id=&#34;root-cause-matters&#34;&gt;Root cause matters&lt;/h1&gt;
&lt;p&gt;When I was a new software manager at Amazon, a jr. developer (an intern that also worked part-time through the year), took down our website. I talked with the jr. developer and told them not to push changes into prod without first clearing it with a senior developer. Two weeks later, a different jr. developer took down the website. I talked with that jr. developer and told them not to push changes into prod without first clearing it with a senior developer. Another two weeks later, yet another jr. developer did the same thing. This time my skip-level (aka boss&amp;rsquo;s boss) talked (i.e., yelled) at me, why was the website down again?&lt;/p&gt;
&lt;p&gt;I learned many of life&amp;rsquo;s lessons through failure and this is how I learned about Amazon&amp;rsquo;s Correction of Error (COE) process. When a problem occurs, you ask &lt;a href=&#34;https://en.wikipedia.org/wiki/Five_whys&#34;&gt;5 Whys&lt;/a&gt;, and get down to the root cause. You then create mechanisms to prevent not only that error, but that entire class of errors from occurring again.&lt;/p&gt;
&lt;p&gt;The danger of bringing up examples like tobacco is we&amp;rsquo;ve come to look back in hindsight and think of them as cartoon villains. They were obviously evil right? If I&amp;rsquo;m a growth engineer at an LLM company, I know I&amp;rsquo;m not evil, so does that mean I can do no harm? A focus on root causes allows us to move past simplistic narratives of heroes and villains. It shifts your focus from individuals and their good intentions (e.g., the jr developer) to the systems (e.g., preventative checks should be automated). A/B tests aren&amp;rsquo;t the problem. Blindly optimizing for short-term engagement metrics like time spent, views, or likes can be though if you don&amp;rsquo;t understand the longer-term consequences. When you don&amp;rsquo;t fix root causes, don&amp;rsquo;t be surprised when problems come up again&amp;hellip; and again&amp;hellip; and again&amp;hellip;&lt;/p&gt;
&lt;h1 id=&#34;we-can-do-better&#34;&gt;We can do better&lt;/h1&gt;
&lt;p&gt;I love A/B testing, I love the puzzles of understanding user behavior, and, frankly, I am excited about the potential of AI. Hard truths most often come from a place of love; it is because we want what we love to be better.&lt;/p&gt;
&lt;p&gt;What I am asking for is simple but not easy: If you build a product, you are responsible for understanding its long-term impact on users. You are responsible for collecting and understanding qualitative feedback by talking to and observing the people who use your product. It is not good enough to say &amp;ldquo;we aren&amp;rsquo;t aware of any harms&amp;rdquo; because you didn&amp;rsquo;t spend the time to study it. Instead, the burden should be on the builder of the product proving their product isn&amp;rsquo;t harmful, and mitigating what harm they do discover. That burden is especially important when you are repeating patterns that we know have caused harm in the past. I&amp;rsquo;ve had these discussions many times with people in tech and a common defense is to bring up consumer responsibility; people freely choose to use these products. When I bring up the comparative need for professional responsibility, it is funny how quickly people are to turn around and absolve themselves of said responsibility. Imagine if structural engineers took the same stance: &amp;ldquo;it&amp;rsquo;s not my fault if people choose to live in unsafe buildings, that&amp;rsquo;s just the free market!&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;I am not just asking for your good intentions; are we willing to put in place the mechanisms to prevent what we know has caused harm? Will we take responsibility for what we build? Or will we pretend short-term engagement metrics always mean long-term value for the people using our products, despite repeated evidence to the contrary?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are we cooked?</title>
      <link>https://www.bonnycode.com/posts/are-we-cooked/</link>
      <pubDate>Wed, 16 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/are-we-cooked/</guid>
      <description>&lt;p&gt;My students frequently ask me what LLMs mean for them as future software developers and data scientists. With little exaggeration it often comes across something along the lines of &amp;ldquo;low-key, are we cooked?&amp;rdquo;. The last one, if you are not one of my students, translates in millennial to &amp;ldquo;good esteemed professor, tell me true, are we f#@ked?&amp;rdquo; While I&amp;rsquo;ve given various off-the-cuff answers, I feel inspired to be more thoughtful in putting down more complete thoughts.&lt;/p&gt;
&lt;h1 id=&#34;some-personal-background&#34;&gt;Some personal background&lt;/h1&gt;
&lt;p&gt;I want to start by giving a little personal history and just saying I understand the anxiety. I started my freshman year at CalPoly San Luis Obispo in Computer Science in September 1999. Like many of us older millennials that got into tech, I had been programming since elementary school (QBasic!) and computer science seemed a natural path. I always loved reading philosophy though and I seriously considered getting a philosophy degree instead. It was a choice between something I figured I was pretty decent at and could make money doing (computer science) and something that I was personally invested in but probably couldn&amp;rsquo;t make money with (philosophy). Earning a living won out over passion. I stuck with computer science, but I took as many philosophy classes as I could get into. To the extent that I was put on academic probation, not because my grades were too low, but because in the words of the admin &amp;ldquo;stop taking so many philosophy classes and just graduate!&amp;rdquo;. Good times…&lt;/p&gt;
&lt;p&gt;Within a year of starting my degree, the tech market fell out. March 2000, we saw the dotcom bust, and here I was a computer science student, kind of doing it for the money, kind of not, and my sure bet didn&amp;rsquo;t seem so sure anymore. We also saw a revival of the perennial bugaboo for American software developers: outsourcing. Every decade brought fresh panic that all programming jobs &lt;a href=&#34;https://developers.slashdot.org/story/04/10/15/1521231/us-programmers-an-endangered-species?sbsrc=thisday&#34;&gt;would&lt;/a&gt; &lt;a href=&#34;https://forio.com/about/blog/pitfalls-of-outsourcing-programmers/&#34;&gt;move&lt;/a&gt; to &lt;a href=&#34;https://www.nytimes.com/2003/12/07/business/business-who-wins-and-who-loses-as-jobs-move-overseas.html&#34;&gt;India&lt;/a&gt;, that American developers were too expensive, that we&amp;rsquo;d all be obsolete. I had to eat and had done a combination of construction and IT jobs up until that point and I was quickly burning through the savings I had built up from working. Luckily, I was able to convince one of my professors, Dr. Clint Staley, to whom I am forever grateful for many reasons, to let me interview for a startup he was running. Working that part-time while I went to school I was able to pay for myself, and momentum carried me forward to finishing my degree.&lt;/p&gt;
&lt;h1 id=&#34;are-we-cooked&#34;&gt;Are we cooked?&lt;/h1&gt;
&lt;p&gt;The best part about teaching in a university is you get to ramble. It is the single most defining characteristic of professors. But I&amp;rsquo;m sure at this point my students are asking: can you get to the point, are we cooked or not? I consider myself a skeptical optimist at heart. Meaning, I&amp;rsquo;m not inclined to believe that change is bad, but I&amp;rsquo;m also more cautious about predicting the future than others. Straightforwardly, that leads me to an answer of no, I don&amp;rsquo;t think you are cooked, but that doesn&amp;rsquo;t mean I can tell you with great certainty how things will play out. What I can do is point you towards the toolkit for how to make better decisions here.&lt;/p&gt;
&lt;h1 id=&#34;embracing-uncertainty&#34;&gt;Embracing uncertainty&lt;/h1&gt;
&lt;p&gt;Life is filled with uncertainty. Many people react irrationally to uncertainty, avoiding it too much or betting too much on luck. Learning how to deal rationally with uncertainty can give you an advantage throughout your life.&lt;/p&gt;
&lt;p&gt;From 2010 to 2016, I built and then led the supply chain and capacity planning systems for AWS Infrastructure. My biggest lesson is dollar for dollar, people are overly biased towards investing in prediction when they are often better suited to invest in flexibility. Time series forecasting tools take the past and extend it out to the future. The further out you go, the more variance you get. And black swan style events, like when &lt;a href=&#34;https://spectrum.ieee.org/the-lessons-of-thailands-flood&#34;&gt;Thailand becomes flooded&lt;/a&gt; and you lose a healthy portion of the world&amp;rsquo;s hard-drive manufacturing capacity, are not frequent enough to learn from in a predictable way. Better to get a good enough forecast, but instead focus on shortening your lead-times, making your supply fungible—meaning interchangeable and adaptable to different uses—and late-binding your decisions as much as possible.&lt;/p&gt;
&lt;p&gt;The parallel to career planning is direct. You can spend a lot of time trying to accurately predict where LLMs will take the industry and the job market. But that will quickly hit diminishing returns. I would instead approach the question from the other angle: what skills are most likely to be durable and fungible—that is, transferable and valuable across different contexts—in a wide variety of potential outcomes? Going whole hog into &amp;ldquo;I&amp;rsquo;m going to build my career around being a React developer&amp;rdquo; is betting on one very specific outcome. If it pays off, great, you can probably command a premium if you turn out to be one of the world&amp;rsquo;s best React developers. But what happens when React joins jQuery in the graveyard of once-essential frameworks?&lt;/p&gt;
&lt;h1 id=&#34;an-interlude-about-koalas&#34;&gt;An Interlude about Koalas&lt;/h1&gt;
&lt;p&gt;When I graduated from college, I went to work for Lawrence Livermore National Labs as a computer scientist. I was working on translating large-scale semantic graph algorithms into usable interfaces for intelligence analysts. I had personally received an award from the Secretary of Homeland Security. We had the academic freedom to explore whatever angles we wanted. There was little pressure to meet deadlines. It felt like a safe and secure job for life working in my little niche. My former professor and boss, Dr. Staley, called me up and said his new startup was just acquired by some struggling online bookseller called Amazon. I wasn&amp;rsquo;t super interested, as I could see existing in my current niche for my whole life.&lt;/p&gt;
&lt;p&gt;He convinced me to join by telling me a story about koalas. Koalas primarily subsist on eucalyptus leaves. Most other animals don&amp;rsquo;t eat eucalyptus, because they have little to no nutrition and they are kind of toxic. But koalas have built their entire evolutionary strategy around being the ones to eat eucalyptus leaves. This has been a great and successful strategy for koalas. But what happens if the eucalyptus forest goes away? Koalas are screwed. Does that mean koalas are actually in danger? No, but it does mean their fate is entirely bound to that one food source existing, while an animal like a rat can happily live and thrive in many ecosystems and is thus much more resistant to shocks in any given ecosystem.&lt;/p&gt;
&lt;p&gt;For some reason, that story convinced me to give Amazon a chance. Rather than focusing on a more niche area as defining &amp;ldquo;what I did&amp;rdquo; like &amp;ldquo;I&amp;rsquo;m the person who designs usability for mathematically intensive applications,&amp;rdquo; I instead built my career around solving hard technical problems regardless of the area.&lt;/p&gt;
&lt;h1 id=&#34;what-are-those-fungible-skills&#34;&gt;What are those fungible skills?&lt;/h1&gt;
&lt;p&gt;When I look back at the skills I learned in university, many of the specific technologies I learned never got used. I learned all about expert systems, but never built an expert system. I learned all about OpenGL, never used it. What I learned from my computer science courses that stuck was the more fundamental ideas of how to think about hard technical problems and create simple, workable solutions to them. For this reason, I often recommend to students who ask me which classes to take that it is more important to take a class that is difficult with a high degree of rigor that challenges you than to focus on any particular domain. Surprisingly, in retrospect, I&amp;rsquo;ve gotten as much use out of the philosophy classes I took—that CalPoly tried to kick me out for taking too many of—as I did my computer science classes. Learning critical thinking skills, how to navigate difficult ethical situations, how to communicate difficult ideas. When Amazon asked me to design a system that could fairly allocate scarce resources across competing teams, it wasn&amp;rsquo;t my coding skills that mattered most—it was my ability to think critically about the problem space and use data to understand and communicate trade-offs to executives who each thought their project was most important. What I&amp;rsquo;d say is my computer science skills were 95% of what initially got me in the door, but it was my liberal arts skills that dominated my later career.&lt;/p&gt;
&lt;p&gt;So my answer is, whatever you do, take on challenging problems, regardless of the area, so you can learn the meta-cognitive skills to understand how you learn and face up to these challenges. Learn critical thinking and how to tear apart problems to turn them from intractable to tractable. And don&amp;rsquo;t neglect the human-side of building your ability to communicate and deal ethically and fairly with others.&lt;/p&gt;
&lt;p&gt;Yes, LLMs are different from outsourcing or the dot-com bust. They can actually write code—not just cheaper, but instantaneously. And yes, I’ve seen the headlines: &lt;a href=&#34;https://www.washingtonpost.com/business/2025/03/14/programming-jobs-lost-artificial-intelligence/&#34;&gt;27% of programming jobs are gone&lt;/a&gt;, &lt;a href=&#34;https://wallstreetpit.com/127073-150k-software-engineer-turned-doordasher-after-800-ai-rejections/&#34;&gt;engineers facing hundreds of rejections&lt;/a&gt;. While I’m skeptical that this disruption is solely due to LLMs (e.g., a mix of post COVID overhiring, interest rate hikes, and broader economic shifts) there’s no doubt that a painful market correction is underway. But remember: every technological disruption feels unprecedented while it’s happening. The telephone operators watching automatic switches get installed thought their &lt;a href=&#34;https://thehistoryinsider.com/rise-fall-of-telephone-operators/&#34;&gt;world was ending&lt;/a&gt;. They were right about their specific job—wrong about their ability to adapt. The question isn’t whether LLMs will change things—they will. The question is whether you’ll be a koala or a rat when they do.&lt;/p&gt;
&lt;p&gt;So no, you&amp;rsquo;re not necessarily cooked. But you might be if you specialize too narrowly in whatever framework or language seems hot today. The jobs that are available will be different, and many of the existing software roles will not exist, at least in their current form. Build skills that transfer. Solve hard problems. Learn to think, not just code. The future needs people who can work with AI, not be replaced by it. And that future is built on the same foundation it always was: adaptability, critical thinking, and the uniquely human ability to navigate uncertainty with wisdom rather than fear.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to be a better software manager</title>
      <link>https://www.bonnycode.com/posts/how-to-be-a-better-software-manager/</link>
      <pubDate>Sun, 16 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/how-to-be-a-better-software-manager/</guid>
      <description>&lt;p&gt;“My dev team is failing, what software process should we use to be more successful?”&lt;br&gt;
“My dev team keeps missing their deliverables, what task management software should I use so they hit their commitments?”&lt;br&gt;
“I’m not a very fast runner, what shoes should I buy to make me faster?”&lt;br&gt;
“I’m a horrible cook, what knife should I use to make a really tasty meal?”&lt;/p&gt;
&lt;p&gt;I get asked variations on these questions several times a month. You’d think by now I’d be better at answering them. Sadly, I still get this flutter of panic when I hear these questions where I run through my head the best way to unwind the web of assumptions behind these questions. This is where I begin visibly grimacing and possibly sighing. I then start responding with something like “well…. it depends… hmm…” And then I feel guilty for dodging the question when clearly they just want a simple answer and why won’t I just tell them the secret?&lt;/p&gt;
&lt;p&gt;The problem is software process, task management software, shoes, and knives are just tools. Having horrible tools can lead you to fail, but having great tools doesn’t make you succeed. What most people don’t want to hear is that success has more to do with preparation, persistence and a lot of hard work. There is no secret. I have learned a few lessons over the years though, and what follows is what I consider to be important when leading a successful development team.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You don’t manage a bad team to be good, you build a good team and it mostly ends up managing itself. People always tell me that the things I do only work because I have a good team. That is because at least 40% of my time is spent on strictly building the team. Recruiting, mentoring, coaching, training. These activities take time to come to fruition and hard work, so don’t expect immediate results. Your persistence will pay off though. One of the best ways to build your team is by giving them accountability so they can practice exercising good judgement. Too many managers hoard decision making, prioritization and return on investment analysis. For example, make someone on your team accountable for the operational excellence of your team. Work with them to establish metrics for their success, have them come up with and prioritize the activities that will improve operational excellence. Be their mentor or find them a good mentor so they are setup for success in their role, but don’t undermine their authority by overriding them. Do this with as much of your manager responsibilities as you possibly can and constantly give your team members more accountability as they grow. Keep doing it until you worry that you’ll have nothing left to do yourself.&lt;/li&gt;
&lt;li&gt;Craft a long, medium and short term vision by deeply understanding your customers. On each of these time horizons, members of the team should be able to answer the question “What value is my team providing?” and “What value should my team provide?” Ask yourself how your team can be even better. How could your team create even more value? Don’t just do this in a bubble but get out there and learn more about your customers. Read individual customer feedback and piece together patterns that allow your team to deliver even greater value. This isn&amp;rsquo;t a one time activity but a never ending journey of both refining your team&amp;rsquo;s vision and building relationships with your customers.&lt;/li&gt;
&lt;li&gt;It is critical that you understand the role of trust in creating your process. 90% of the process development teams build up is due to a lack of trust, both within the team and between the team and others. Detailed specifications are asked for because the people asking for functionality don’t trust the developers to build the right thing. Commitments are asked for because people don’t trust the developers to work hard and on the right priorities. These process artifacts take time though that take away from the time the team could be spending on creating more value. Ask yourself, is it possible that by building more trust we can run a lighter process that spends more time on creating value? This question should be approached honestly because the answer isn’t always yes but frequently is.&lt;/li&gt;
&lt;li&gt;Manage complexity through iteration, not planning. Most software is not simple and unambiguous. If you are have people using your software directly, it is almost guaranteed to be complex. Humans and their organizations are infallible generators of complexity. The more ambiguous or complex the problem the more aggressive you should be about iteration. Aggressive iteration means being unafraid of throwaway work for the sake of getting a feature out earlier. Aggressive iteration means actually getting the software used though, an unused feature is a feature you aren’t learning from. As a side benefit, iteration is a powerful way to generate trust with customers and management. A productive development team that is regularly demonstrating working, valuable functionality will be more appreciated and have more autonomy.&lt;/li&gt;
&lt;li&gt;Establish a planning horizon for your team that matches your business. Fast iteration isn&amp;rsquo;t an excuse for short term thinking. In my experience too many managers sacrifice long term value chasing after short term results. You need to consider the long term ramifications of your decisions. What is considered long term should match the context of your business. If you are in a fast moving startup that is trying to be the first to market, you should probably optimize for something closer to a 3 month planning horizon than a 3 year horizon. The shorter the planning horizon, the more you can ignore trust issues, technical debt, operational inefficiency, etc. because none of those will matter unless you have a successful product. On the other hand, if you are in a more stable environment with a long planning horizon, a heavy investment in operational efficiency and building trust will pay dividends and be much more cost effective in the long run.&lt;/li&gt;
&lt;li&gt;A team needs a way to understand their long term success. The mistake most people make is they focus first on what is measurable rather than what is important. This leads to ridiculous measures of value like lines of code, story points, estimated accuracy, etc. It can be hard to wrap your head around what success looks like though. Engage your team, your own managers and your customers with the same question. Eventually you&amp;rsquo;ll come to a true measure of your success. The benefit of having that measure goes beyond just knowing what success looks like though. It gives your team autonomy in how they accomplish that success. Without a valid measure of success, your team will be more subject to signing up for arbitrary project deliverables. With a measure of success though, you can commit yourself to that end result, but maintain the freedom along the way in the best way to accomplish it.&lt;/li&gt;
&lt;li&gt;Have fun, be ethical and treat people with respect. Seriously. You have only one life to live and the only measure of a well lived life is to be a good person doing good things. Never sacrifice that for creating more business value or other worldly success. I once worked for a company with massive internal strife. We argued endlessly about minutiae that seemed important at the time, gossiped, disrespected and hated each other. Everyone thought everyone else was an idiot. Then one day in the middle of all this we got called into a conference room to be told that our entire division had been laid off. All of a sudden our petty disagreements all went out the window and I once again saw my former coworkers as people again. I’m not saying to be soft, if someone isn’t delivering on a team then that needs to be dealt with, but that is never an excuse for disrespect.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And now you know what I’ve learned so far about how to lead successful software development teams.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A time to dream</title>
      <link>https://www.bonnycode.com/posts/a-time-to-dream/</link>
      <pubDate>Sun, 27 Oct 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/a-time-to-dream/</guid>
      <description>&lt;p&gt;My success in life is based on my love and respect for daydreaming. I&amp;rsquo;ve always been a daydreamer. At the age of seven, I envisioned a space opera of powerful Lizians, Heart Monkeys and Star People who fought against the tyrannical Lizard Men. I loved this world and I visited every chance I got. I spent so much time fleshing out my world rather than school work that by the end of high school I had a written a truly intricate science fiction novel and I had the poor grades to show it. It was also an amazingly horrible novel. When I showed it to a girl I liked in high school, because high school chicks dig sci-fi authors, I couldn&amp;rsquo;t have anticipated the reaction, “I can&amp;rsquo;t believe you waste your time dreaming about stupid stuff like this.”&lt;/p&gt;
&lt;p&gt;To this day, I still waste most of my time “dreaming about stupid stuff.” Most of those dreams now involve my work rather than fantastical worlds, but the love is still there. I set aside several hours every week to dream about what could be. I sprawl out in these dreams, I linger, and I set no goals for myself in what I hope to accomplish. I ask myself, what would make this amazing? Why would that be amazing? What is the essence of amazingness? I go down every corridor, until I get to the essence of the problem and the solution. This isn&amp;rsquo;t work that can measured; this is my time to enjoy myself and untangle life&amp;rsquo;s truly difficult puzzles. It is during these times that I get excited about the potential of what could be.&lt;/p&gt;
&lt;p&gt;Without this time to dream, my work would have no direction. I would be subject to the whims of whomever is yelling the most at a particular moment or whatever crisis of the week has sprung up. Dreaming builds a vision and a vision creates purpose. When something urgent comes up, I can keep it in the context of whether it is truly more important than the great things I&amp;rsquo;ve envisioned.&lt;/p&gt;
&lt;p&gt;Where many other dreamers go wrong is their dreams stay dreams. I love my dreams, but I also respect them. That respect means that while I set aside time each week to dream, I spend the rest of my week making them happen. I temper my excitement for the amazingness of what could be by telling myself that greatness takes time. So I take the smallest step possible towards the dream that I can put into action. I then dream again the next week, but this time a smarter me is dreaming, informed by the realities of taking that small step forward. That smarter me comes up with an even better dream. Dream and reality march forward together as the work evolves, always daring to dream of perfection while letting reality take its time to get there. This constant cycle of vision and execution is what leads inevitably to success.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Throwaway Code: A Love Story</title>
      <link>https://www.bonnycode.com/posts/throwaway-code/</link>
      <pubDate>Sat, 28 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/throwaway-code/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Throwaway Code&lt;/strong&gt;&lt;br&gt;
THrōəwā kōd&lt;br&gt;
&lt;em&gt;noun&lt;/em&gt; -  Code that is written to launch a feature early, but will later be deleted either due to a future feature or a new process.&lt;br&gt;
The BonnyCode Dictionary of Software Terms&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Not every love story is the same. There is the classic story of love at first sight. The love that feels destined and obvious from the very first moment. Source control was that way for me. I didn&amp;rsquo;t always use source control (gasp!), but I never went back once I did.&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t always love throwaway code. I may have occasionally flirted with throwaway code&amp;rsquo;s prettier cousin, the prototype, but I wouldn&amp;rsquo;t be caught dead with throwaway code. Today though? Throwaway code is one of the most powerful tools for a software developer. If I was on a desert island, and I was for some reason forced to do software development on that island, and for some reason I was limited in what abstract concepts I could take with me to that desert island, I would take throwaway code. And I would take long, romantic, moonlit walks on that beautiful desert island beach with throwaway code.&lt;/p&gt;
&lt;p&gt;How did I go from hating throwaway code to being soul mates? Throwaway code is so important because it is what makes iterative software development possible. The reason throwaway code is unappreciated, even in this age of Agile development, is because people don&amp;rsquo;t understand what it means to develop iteratively. Scientists have classified 3 stages of iterative development:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stage 1: Pretending&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When most teams first try scrum (aka Agile with training wheels), they take a surface level approach to the process. They pick some short iteration cycle, 1-week, 2-weeks or a month. Strangely, nobody ever picks 3-weeks. Anyways, they then run the same process they always did, they just associated the work with whatever iteration is in flight. For example, a sprint planning meeting will go something like this:&lt;/p&gt;
&lt;p&gt;“What are you working on this sprint?”&lt;/p&gt;
&lt;p&gt;“We are first working on testing the new Bear Translator functionality developed in the last sprint. We are then finishing up coding on the Bear Imagine functionality that we started two sprints ago but got delayed.”&lt;/p&gt;
&lt;p&gt;In the pretend stage of iterative development, iterations are treated more like time labels for when work occurred and a way of determining how often to have meetings to discuss what to work on. The work itself isn&amp;rsquo;t driven by the iterations though.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Stage 2: Done Done&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Teams advance from the pretending phase of iterative development to the done done phase. This phase is characterized by the following exchange occurring several times a sprint:&lt;/p&gt;
&lt;p&gt;“Is the Bear Translator done?”&lt;br&gt;
“Yes”&lt;br&gt;
“Is it done done?”&lt;br&gt;
“No”&lt;/p&gt;
&lt;p&gt;This makes up for the failings of the pretend stage by emphasizing that the goal is to finish work inside of the sprint boundaries. It enforces a good discipline on the team to finish features. There is a heavy emphasis in this stage on time-boxing. Unlike the previous stage, the time-boxed sprint becomes the main driver for how work is broken up and assigned.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Stage 3: Customer Use&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The final stage of iterative development moves from the frame of reference away from time-boxes towards minimizing the time before a customer gets value from the software. A typical exchange follows:&lt;/p&gt;
&lt;p&gt;“The Bear Translator feature is finished! Let&amp;rsquo;s party!”&lt;br&gt;
“That&amp;rsquo;s great, how many people have used it?”&lt;br&gt;
“Nobody, we don&amp;rsquo;t have a UI for interacting with it yet. We&amp;rsquo;ve only deployed the backend work.”&lt;br&gt;
“Party is over everyone, the feature isn&amp;rsquo;t actually finished.”&lt;br&gt;
&amp;lt;collective groan, people throwing red plastic cups at the developer for being lame&amp;gt;&lt;/p&gt;
&lt;p&gt;This stage emphasizes building the minimal customer-valuable feature and then iteratively building on that to provide more value. The training wheels are off at this point and the sprint time-boxes are no longer necessary. The discipline learned from progressing through Stage 2 is useful at this point though because the emphasis needs to remain on finishing features.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Most software teams are stuck somewhere between stages 1 and 2 of iterative development. Throwaway code appears as waste in these first two stages. If total value of a feature is measured as a typical manufacturing formula (Total Value = Manufacturing Rate * Value of Good), then any code that is thrown away is a loss on the expected total value. The secret to iterative development comes down to one concept. And it has little to do with the time-value of money or economic order quantities.&lt;/p&gt;
&lt;p&gt;The reason why iterative development is important is because s&lt;strong&gt;oftware requirements aren&amp;rsquo;t known until the software is used by customers.&lt;/strong&gt; I no longer say this phrase around experienced developers because it provokes an uncontrollable reaction to tell me war-stories about just how true it is. The period between software development and customer use is when software can go off track. The smaller you make the cycle between the two, the more likely you are developing the right thing. These constant checkpoints make sure you are pointed in the right direction.&lt;/p&gt;
&lt;p&gt;To get an intuitive sense of just how critical this is, you can try the following experiment at home. Get in your car (a bike will also work) and drive to a part of town you&amp;rsquo;ve been to before.&lt;/p&gt;
&lt;p&gt;First, to simulate non-iterative software development: while driving, close your eyes for 1 minute and open them for minute, then close them for a minute, etc. You&amp;rsquo;ll find that when your eyes were closed, you probably ran into a building, ran stop lights, endangered many lives including your own.&lt;/p&gt;
&lt;p&gt;Second, if you are still conscious, simulate iterative software development: while driving, close your eyes for 1 second, then open them for 1 second, etc. Despite your eyes being closed for the same amount of time as in the first example, you likely never ran off the road and, if you did hit someone, you probably meant to do it.&lt;/p&gt;
&lt;p&gt;This is the difference between iterative development and non-iterative development. You know that you are on track because you are getting constant feedback. And you are getting that feedback where it matters, from the people that will use your software. Iterative development is so critical to staying on track that I will write copious amount of throwaway code to make iterations short. The ironic thing is, the people that avoid throwaway code end up writing the most in the end. They just do it unintentionally because they write large amounts of code that never gets used because their feature was off-track from the beginning.&lt;/p&gt;
&lt;p&gt;I love writing throwaway code because it is this beautiful launch vehicle to get the code I want to last out there and used immediately. When I actively make the decision to write it, I know there is a good chance I&amp;rsquo;m on the right track.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cost benefit analysis for bear lovers</title>
      <link>https://www.bonnycode.com/posts/cost-benefit-analysis/</link>
      <pubDate>Sun, 25 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/cost-benefit-analysis/</guid>
      <description>&lt;p&gt;Feature estimates are often blindly used for cost benefit analysis. This was no more apparent than when I once worked with a product manager named Bethany. She was responsible for what, in hindsight, was always a doomed social network for lovers of the North American Brown Bear. Bethany would routinely ask her developers to provide implementation costs for a long list of features. The developers would grumble and complain they need more detailed requirements before they can put together detailed estimates (because they had been burned in the past on being held to commitments based on changing scope). Bethany retorts that she just needs “T-shirt sizes”, which is code for wild ass guesses, so she can do cost benefit analysis. Logically, this makes sense. Like any savvy businesswoman, the product manager wants to get a return on her investment. You wouldn&amp;rsquo;t buy a piano without first knowing the price, right?&lt;/p&gt;
&lt;p&gt;The developer would always eventually relent and give her the feature estimates she asked for. The feature to let people upload pictures of their favorite bear for example would take 2 weeks to build. The feature to translate English into Bearease was estimated to take between 1 month and 2 years. The bear picture upload feature was a clear customer win and a frequent ask from the sites three customers, but the English to Bearease language translation was a real opportunity to differentiate their site from the other bear lover social networks. If the bearease translation feature cost only 1 month it made more sense to prioritize that feature, but not if it took 2 years.&lt;/p&gt;
&lt;p&gt;Bethany went back to the developers and asked why there was such a wide estimate in the translation feature and if there was a way to bring it down to the 1 month side. The developers came back with a bunch of mumbo jumbo about corpuses and having to maintain the translator by hand. They could develop a version of the feature in 1 month, but they wanted to do something fancier. Bethany heard that it could be done in 1 month if they really wanted to and said “go forth and develop my Bearease translator.” (she literally said that, it was weird then and it is weird now)&lt;/p&gt;
&lt;p&gt;A month later, as expected, the developers had cranked out a Bearease translator just like they said they would. Bethany and the developers had a big launch party, people drank a bit too much and they talked about all the money they were going to make when the site went IPO.&lt;/p&gt;
&lt;p&gt;Horribly hungover (likely due to the preponderance of blended whisky drinks), Bethany then tasked the developers to start working on the bear picture upload feature she had put off earlier. The developers went to work and two weeks later Bethany came back to check in on their launch. The developers said they were still working on it, and it would take them another two weeks. Bethany was furious. The feature was only supposed to take 2 weeks, she demanded to know why they couldn&amp;rsquo;t make their commitment. The developers started venting about how they were spending half their time maintaining the Bearease translator, constantly adding new words to the dictionary as users tried to translate words that they didn&amp;rsquo;t already have translations for. Bethany was angry at the developers for not being able to develop new features quickly enough and the developers were similarly angry they were spending so much of their time maintaining dictionaries rather than coding new features. They spent so much time being angry with each other that they stopped developing features all together. Facebook swooped in and stole their Bear loving user-base (with the ability to upload &lt;a href=&#34;http://upload.wikimedia.org/wikipedia/commons/6/6e/Bearclaw2.jpg&#34; title=&#34;Bear manicure&#34;&gt;bear pictures&lt;/a&gt; even!), and the rest is history.&lt;/p&gt;
&lt;p&gt;Bethany and the developers took away opposite lessons from the whole experience. Bethany said working with developers is lame because they are lazy and don&amp;rsquo;t understand business. She started her own hedge fund and now has a net worth measured in billions of dollars. The lesson the developers pulled from the experience was to never again do a feature quick and dirty, and the next time a product manager asks them to build a Bearease translator, they will say it takes 2 years, end of story.&lt;/p&gt;
&lt;p&gt;While Bethany can now afford to send several teams of highly trained ninja assassins my way for saying this, I put forth the contention that both Bethany and the developers pulled away the wrong lesson. Bethany&amp;rsquo;s real mistake was equating implementation cost with the true cost of a feature for cost benefit analysis. Software features, like most business investments, have operating costs associated with them. Those operating costs can vary wildly and there is frequently a trade off between initial investment cost and operating cost. If Bethany had taken into account the full cost of the features, she may have decided that uploading bear pictures was actually the wiser investment (something Facebook was smart enough to pick up on). Or at least she would have come in with the right expectation on what she was getting with her initial Bearease translator, and budgeted for followup work to make the feature more operationally maintainable if it was a success.&lt;/p&gt;
&lt;p&gt;The developers on the other hand learned too simplistic a lesson on technical debt. Technical debt, like any form of debt, is not evil. Without the ability to go into debt (i.e., taking out a loan), most new businesses couldn&amp;rsquo;t even get off the ground in the first place. If the demand for a Bearease translator was uncertain or if the immediate rush to market of being the first to have a Bearease translator justified it, the one month implementation with high technical debt could absolutely be the correct decision. For example, if they launched the Bearease translator and it completely tanked, they at least would have only lost out on 1 month of work rather than 2 years worth of work. Requirements and customer adoption are so subtly variable and changing in software development that this is often in fact the best approach to take. As long as ongoing operational cost is measured and time is continuously budgeted to reduce it, everyone can benefit from such a rapid iteration methodology.&lt;/p&gt;
&lt;p&gt;This post is also available in spoken &lt;a href=&#34;https://www.bonnycode.com/posts/rawr/&#34;&gt;Bearease&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Grr</title>
      <link>https://www.bonnycode.com/posts/rawr/</link>
      <pubDate>Sun, 25 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/rawr/</guid>
      <description>&lt;p&gt;RAWWR!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How feature estimates killed Bobo</title>
      <link>https://www.bonnycode.com/posts/feature-estimates/</link>
      <pubDate>Sun, 24 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/feature-estimates/</guid>
      <description>&lt;p&gt;Software development lacks a single meaningful, objective productivity metric. This is not for lack of trying. A productivity metric would make the life of a software development manager dramatically easier. Performance reviews? Just see who has the highest number. Need to find out how to boost productivity? Find the developer with the best process and have your other developers adopt it as a best practice. And so, managers grasp for measurement. Lines of code is so obviously wrong as a measurement that I&amp;rsquo;ve mostly heard it brought up for its comedic value. I&amp;rsquo;m not saying that in the history of software there hasn&amp;rsquo;t been some misguided manager who actually reviewed their developers by lines of code, but it is certainly more myth than reality in the modern era.&lt;/p&gt;
&lt;p&gt;I can&amp;rsquo;t say the same for effort estimation accuracy. Many otherwise intelligent managers have embraced the accuracy of their developers estimates as a defining measure of their developers worth. There are varying degrees of vigor attached  to this review. The energetic manager maintains a spreadsheet (or enlists a task tracking tool) to calculate every estimate given by their developer and then what the task actually came in at. At its most simplistic they might just divide the two numbers at that point and shoot see who deviates the most from 1 and apply the appropriate corrective action.&lt;/p&gt;
&lt;p&gt;Most managers aren&amp;rsquo;t quite so vigorous though. The belief in holding developers accountable to effort estimate accuracy is frequently enforced more subjectively.&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Filbert, it looks like you&amp;rsquo;re past several features have all come in late. You need to start pulling your weight. Part of being a professional software developer is reliably hitting your commitments.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;And it&amp;rsquo;s true isn&amp;rsquo;t it? Promise you do something and then not do it and you&amp;rsquo;ll lose trust. The problem is why are software effort estimates treated as commitments in the first place? Most of this comes from the belief that deadlines are a necessary motivator. Modern society revolves around time starting with grade school. Teachers hand out homework and assign due dates.Tests are given at set times and students are taught to cram. This same philosophy extends to college and then to work. Without the pressure of time, people are trained to slack off. And so we create artificial deadlines as a motivational tool.&lt;/p&gt;
&lt;p&gt;And for some lines of work, that is necessary. Because a lot of work is really boring. But creating software is fun! Sure, it has its slow moments, but the best in the field are here because they love it. For an already self-motivated developer, the addition of the deadline constraint doesn&amp;rsquo;t make any additional work occur. It just prioritizes that dates are more important than quality.&lt;/p&gt;
&lt;p&gt;Hold up says the man in the back. I&amp;rsquo;m not making these estimates up, the developer is. I&amp;rsquo;m just asking them to reliably deliver. If I tell my boss I could have a budget out by next week, I&amp;rsquo;d be fired if I gave it to him a few weeks later. But again you get to the question of why this accountability matters. We always look to latch onto some more well established parallel for software development to better understand how we should treat it. Let&amp;rsquo;s flip that around and treat another field like software.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s say that you own a craft dutch clog workshop. You have two shoe makers, Bobo and Jobo. Bobo says every day he is going to make 100 shoes and ends up making between 25 to 50. Jobo says he is going to make 5 shoes and always makes 5. The quality is exactly the same for both workers. There is such hot demand for the shoes that as soon as one is made it just flies off the shelves as &lt;code&gt;$200 per shoe&lt;/code&gt;. Both Bobo and Jobo are paid the same hourly wage of &lt;code&gt;$100/hour&lt;/code&gt; and the material cost for each shoe is &lt;code&gt;$10&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;From a naive cost perspective, Bobo makes shoes at a cost of &lt;code&gt;$10+(($100*8 hours)/(25 to 50))&lt;/code&gt; or &lt;code&gt;$26 to $42&lt;/code&gt;. For simplicity, let&amp;rsquo;s say that Bobo&amp;rsquo;s range of shoes made per hour follows a standard distribution so his average cost per shoe is &lt;code&gt;$31&lt;/code&gt;. Jobo makes shoes at a cost of &lt;code&gt;$10 + (($100*8 hours)/5)&lt;/code&gt; or &lt;code&gt;$170&lt;/code&gt;. Given their respective production rates, Bobo makes you a profit of &lt;code&gt;($200 - $31)*(25 to 50)&lt;/code&gt; or around &lt;code&gt;$6,000 per day&lt;/code&gt;. Jobo makes you a profit of &lt;code&gt;($200 - \$170)*5&lt;/code&gt; or &lt;code&gt;$150 per day&lt;/code&gt;. Now a lean manufacturing guru might say that Jobo is still better because reliability is more important than total throughput. Otherwise you end up with overproduction in one part of the system which then has associated inventory costs and other wastes. But in this case, that isn&amp;rsquo;t quite valid because both Bobo and Jobo are making the end product. And there is no inventory cost because the shoes sell as fast as they are made.&lt;/p&gt;
&lt;p&gt;In the end, Bobo makes his employer over 40 times as much money as Jobo does. Now let&amp;rsquo;s bring in the traditional software manager that uses estimate accuracy as their primary means of driving accountability. Jobo delivers to his estimates 100% of the time and is the model employee. Bobo though is a problem case. He is unreliable and is off on his estimates from 2x to 4x. After sending Bobo to an estimation training for 2 weeks, Bobo now estimates that he makes 37 shoes per day. And while on average this is correct, Bobo still sometimes makes as low as 25 clogs some days and as high as 50 clogs other days. The days he makes 50 clogs he is accused of sandbagging and the days he makes 25 he is just being lazy. This is still much too unreliable. Jobo is still the model employee and is given a raise. Bobo is on a performance improvement plan and asked why he can&amp;rsquo;t be more like Jobo. Bobo eventually gets smart and starts estimating that he can make 25 a day. As soon as he gets to 25 in a day he whips out the hammock and martini and enjoys the rest of his day. Now his estimate accuracy is 100% but his boss is angry that he sees Bobo in a hammock for a significant portion of every day. This is obviously unacceptable. Jobo on the other hand has been given several raises and is given a company luxury car to ensure his retention. Bobo finally realizes his boss doesn&amp;rsquo;t even care how many clogs he makes and just wants estimate accuracy. So he starts making 5 shoes a day like Jobo. He staggers the creation of each shoe slowly through the day and makes sure to always look like he is working. His boss is ecstatic, he is finally reliably hitting his estimates and working hard.&lt;/p&gt;
&lt;p&gt;Bobo quits a week later because he realizes all he ever loved was making clogs and it is mind numbing to work at a place where estimates matter more than the clogs. Bobo&amp;rsquo;s manager is lauded for his top-grading efforts. Bobo starts his own clog shop across the street and starts selling his clogs for &lt;code&gt;$150&lt;/code&gt;, still making a healthy profit. Bobo&amp;rsquo;s old clog shop can&amp;rsquo;t meet this new price without losing money per clog sold. Jobo&amp;rsquo;s manager, realizing the error of his ways and that there is no way he can compete with Bobo&amp;rsquo;s clog shop, murders Bobo and burns down his new shop. Jobo&amp;rsquo;s clog shop continues on for many years with a small but steady profit.&lt;/p&gt;
&lt;p&gt;It all seems so obvious in the world of clogs. But is software really much different or is it just harder to quantify the unit of production than in a world of widgets? It is often said that it is better to have an imperfect measure than no measure at all. But estimate accuracy isn&amp;rsquo;t an imperfect measure for software productivity, it is a completely orthogonal measure that actually drives down productivity. The only reason we are left with holding developers accountable to feature estimates is that their accuracy is necessary for some other purpose, such as the creation of project launch timelines or for cost-benefit analysis. I&amp;rsquo;ll tackle the flaws of these uses in my future posts.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I&#39;m back and I hate your estimates</title>
      <link>https://www.bonnycode.com/posts/i-hate-your-estimates/</link>
      <pubDate>Mon, 11 Jun 2012 00:00:00 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/i-hate-your-estimates/</guid>
      <description>&lt;p&gt;For 2,000 years, ever since the Ancient Greeks got it into their heads that disease was caused by excess fluids, most disease in the western world was treated through bloodletting. Your back hurts? Let&amp;rsquo;s drain a quart of blood and see how you feel! Need to amputate your foot? Better drain some blood first. Was the practice scientifically baseless and actually harmful? Hell yes! There are today some cases where bloodletting is validly practiced, but it is no longer the panacea it once was. Effort estimation is software development&amp;rsquo;s version of bloodletting. Developers use effort estimates to drive accountability, to conduct cost-benefit analysis, to pack sprints, create launch timelines and, I believe in some circles, to summon the nine dark lords of hell.&lt;/p&gt;
&lt;p&gt;But why do we think effort estimates are the solution to all of these problems? Everything about effort estimates in software really is silly. Look at the homegrown rules we&amp;rsquo;ve come up with for estimates. I&amp;rsquo;ve heard more than one grizzled veteran tell me their preferred method is to take their initial estimate, double the number and up the unit of time (e.g., hour becomes day, day becomes week, etc.). This is always said in a semi-joking &amp;ldquo;but, no really, it works&amp;rdquo; tone.  In the 90s highly complicated methods of estimation became popular that involved lots of acronyms and I&amp;rsquo;m sure consultants. Now that agile has taken over the software industry we estimate using planning poker and Fibonacci numbers. The latest estimation technique is to sacrifice a goat and spread its entrails over a large area. Maybe that will finally be the trick that works, but I doubt it because as an industry, despite all these new techniques, we are still no better at estimating.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve invested quite a bit of time at getting better at estimation. And I got a little better. But one day, while knee deep in goat entrails, I stepped back and looked at the whole mess and asked why am I doing this? To what end do we estimate and then re-estimate, pack a schedule just to pack it differently in a month. And at the end of this introspection I determined my life of software estimation had all been a fraud. I&amp;rsquo;d been wasting my time. I moved to Nepal and joined a small temple. And now the secret of why I haven&amp;rsquo;t been working on my blog is out. But after years of meditation I&amp;rsquo;ve decided to come back to the material world and spread my gospel.&lt;/p&gt;
&lt;p&gt;And so, to demonstrate that effort estimates are not only useless but also harmful, I shall attack each motivation on its own. I will start next week with my least favorite reason of all&amp;hellip; accountability!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Just Say &#39;No&#39; To Boring Code</title>
      <link>https://www.bonnycode.com/posts/just-say-no-to-boring-code/</link>
      <pubDate>Sun, 12 Apr 2009 22:51:32 +0000</pubDate>
      
      <guid>https://www.bonnycode.com/posts/just-say-no-to-boring-code/</guid>
      <description>&lt;p&gt;&lt;em&gt;Thanks to &lt;a href=&#34;http://www.cs.uchicago.edu/people/clklein&#34;&gt;Casey&lt;/a&gt; for inspiring this entry and for fighting the good fight against boring code.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I have extreme feelings of dissatisfaction with boring code. Boring code is monotonous and has a low signal to noise ratio. It takes a long time to communicate anything of value in boring code because most lines are dedicated to boilerplate. For example, according to a recent statistic I just made up, 95% of Java code consists of the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;getBlah&lt;/span&gt;() {  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; blah;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;setBlah&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; blah) {  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;blah&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; blah;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;String &lt;span style=&#34;color:#a6e22e&#34;&gt;getSoBored&lt;/span&gt;() {  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; soBored;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;setSoBored&lt;/span&gt;(String soBored) {  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;soBored&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; soBored;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In Ruby, this looks like:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-ruby&#34; data-lang=&#34;ruby&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;attr_accessor&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;:blah&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;:soBored&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you are using Java, a certain amount of this type of verbose code is just necessary. The far more insidious problem is that it trains developers into believing this type of pattern is a good thing. The best thing about Ruby and the functional programming communities is that the first point emphasized is that code should be concise and full of meat and if it isn&amp;rsquo;t you aren&amp;rsquo;t thinking hard enough. For instance, the Hello World program in Ruby:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-ruby&#34; data-lang=&#34;ruby&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;puts &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello, World!&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Straight to the point. In Java, you are already entering the world of boilerplate thinking (from &lt;a href=&#34;http://java.sun.com/docs/books/tutorial/getStarted/application/index.html)&#34;&gt;http://java.sun.com/docs/books/tutorial/getStarted/application/index.html)&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;/**   
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * The HelloWorldApp class implements an application that  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; * simply displays &amp;#34;Hello World!&amp;#34; to the standard output.  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt; */&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;HelloWorldApp&lt;/span&gt; {  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;(String&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; args) {  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        System.&lt;span style=&#34;color:#a6e22e&#34;&gt;out&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;println&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello World!&amp;#34;&lt;/span&gt;); &lt;span style=&#34;color:#75715e&#34;&gt;//Display the string.  &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;My knock here is not actually that Ruby or functional languages magically eliminate all boilerplate code, or that this extra overhead in these cases is really that painful. You can easily use a code generator for both of these situations and if this is the only boilerplate in your code you are doing pretty good. The problem is the Java community teaches its developers that all of their code should be at about this level of signal to noise.&lt;/p&gt;
&lt;p&gt;This is not an argument about aesthetics. Boring code is bad for precisely three reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Boring code is boring to read. Code is read far more than it is written. This means programmers coming in to modify your code are more likely to miss something and then make the wrong code change.&lt;/li&gt;
&lt;li&gt;Boring code is boring to review. A critical quality insurance practice in professional software development is code reviews. But boring code is boring to review. If you write boring code, it is far more likely the reviewer will just go &amp;lsquo;yadda yadda yadda looks good to me&amp;rsquo; and gloss over mistakes.&lt;/li&gt;
&lt;li&gt;Boring code is boring. Come on, do you really want to be boring?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The only thing worse than boring code is &lt;a href=&#34;https://www.bonnycode.com/posts/in-defense-of-duplicated-code/&#34;&gt;magic code&lt;/a&gt;. Stick to the exciting, elegant, simple code, believe me you&amp;rsquo;ll sleep better at night if you do.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
